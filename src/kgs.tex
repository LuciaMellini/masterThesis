\chapter{Knowledge Graphs}\label{kgs}
This chapter presents a comprehensive examination of knowledge graphs, elucidating their theoretical underpinnings and a range of applications. The discussion begins with a formal definition of knowledge graphs in \Cref{definition}-\Cref{inductive-information}, followed by an exploration of their specific applications within the life sciences in \Cref{kgs:biomed}.

\section{Definition}\label{definition}
The concept of knowledge graphs has garnered significant attention since Google's introduction of its Knowledge Graph in 2012, particularly within the realm of Semantic Web research. However, despite their widespread use, a consensus on a singular definition remains elusive, as academic sources provide diverse interpretations. The following definitions exemplify this variation:

\begin{description}
    \item[Structural and compositional aspects] Knowledge graphs are characterized by graph-based representations of information. Paulheim~\cite{Paulheim2016KnowledgeGR} defines a knowledge graph as an entity-focused graph that (i) illustrates real-world entities alongside their interrelations, (ii) establishes classes and relations within a defined schema, (iii) facilitates the interrelation of arbitrary entities, and (iv) encompasses various topical domains. Echoing this, the Journal of Web Semantics~\cite{Kroetsch2016knowledge} characterizes knowledge graphs as comprised of entities, their types, and the relationships among those entities.
    
    \item[Domain-specific representations] According to the Semantic Web Company, knowledge graphs can adapt to represent structures specific to varied fields, encompassing concepts, documents, and datasets.    
    
        \item[Formal definition] Färber et al.~\cite{Farber2016linked} articulate knowledge graphs as RDF graphs (introduced in \Cref{models:directed_edge_labeled_graphs}), composed of RDF terms, that can be represented as a URI ($u\in \mathcal{U}$), a blank node ($b\in \mathcal{B}$), or a literal ($l\in \mathcal{L}$). A RDF graph consists of a collection of $(s, p, o)$ triples, where:
    \begin{itemize}
        \item $s\in \mathcal{U} \cup \mathcal{B}$ denotes a subject,
        \item $o\in \mathcal{U}\cup \mathcal{B}\cup \mathcal{L}$ denotes an object,
        \item $p\in \mathcal{U}$ denotes a predicate
    \end{itemize}
    Here, an 
    
    \item[Dynamic extraction] An emphasis on the automatic extraction of interconnected facts from the web has been presented by Pujara et al.~\cite{Pujara2013KGIdentification}.
\end{description}

The aforementioned diversity in definitions complicates discussions and comparative studies, emphasizing the need for a common definition. In response to this requirement, Ehrlinger et al.~\cite{Ehrlinger2016TowardsAD} propose the following definition for knowledge graphs:
\begin{center}
    \begin{quote}
        A knowledge graph acquires and integrates information into an ontology and applies a reasoner to derive new knowledge.
    \end{quote}
\end{center}
This definition contributes to a unified comprehension of knowledge graphs through three salient aspects:
\begin{description}
    \item[Data integration] Knowledge graphs gather and incorporate data from disparate sources, which renders them both dynamic and expandable.
    \item[Inference capabilities] The employment of reasoning engines facilitates the deduction of new information, thereby augmenting the functionality beyond that of static data repositories.
    \item[Ontological basis] The foundation of knowledge graphs rests on ontological structures, which provide a formal framework for the representation of knowledge and relationships.
\end{description}

Knowledge graphs exhibit a complexity that surpasses that of traditional databases or ontologies, combining the beneficial properties of both to enable automated reasoning and the dynamic incorporation of information. In this context, the functionality and capabilities of knowledge graphs are deemed to be of greater significance than their possible great size.

\section{Data Graphs}\label{data-graphs}
The foundational concept of knowledge graphs is based on the transformation of data into a graph structure, resulting in what is referred to as a \term{data graph}. This methodology confers enhanced flexibility in integrating new data sources, in contrast with relational models, which necessitate predefined schemas. Although tree structures offer similar adaptability, graph structures do not impose hierarchical constraints and allow the existence of cycles. We explore  various graph-structured data models that can be employed to represent such graphs, as listed in~\cite{Hogan2021KGs}. We then describe various enhancements and extensions of the data graph – relating to schema, identity and context – that provide additional structures for accumulating knowledge.

\subsection{Models}\label{models}
The principal graph structures used to represent knowledge graphs are delineated in this section, introducing increasingly complex models.

\subsubsection{Directed Edge-Labeled Graphs}\label{models:directed_edge_labeled_graphs}
A directed edge-labeled graph is composed of a set of nodes and a set of directed, labeled edges interconnecting these nodes. Within knowledge graphs, nodes correspond to entities, while edges represent the relationships between them. 

\begin{definition}[Directed edge-labelled graph]\label{def:directed-edge-labelled-graph}
    Given $\textbf{Con}$ a set of constants used as, a directed edge-labelled graph is a tuple $G = (V, E, L)$, where $V \subseteq \textbf{Con}$ is a set of nodes, $L \subseteq \textbf{Con}$ is a set of edge labels, and $E \subseteq V \times L \times V$ is a set of edges.
\end{definition}

The Resource Description Framework (RDF)~\cite{Cyganiak2014rdf}, as endorsed by the World Wide Web Consortium (W3C)\footnote{More details about RDFs at \url{https://www.w3.org/TR/rdf12-concepts/}}, represents a standard data model. This model specifies node types including Internationalized Resource Identifiers (IRIs)\footnote{Section of the W3C working draft on RDFs regarding IRIs \url{https://www.w3.org/TR/rdf12-concepts/\#section-IRIs}} for global identification, literals for strings and datatype values, as well as blank nodes for anonymous nodes.

\subsubsection{Heterogeneous Graphs}
Heterogeneous graphs provide a generalization of directed edge-labeled graphs by allowing nodes and edges to possess varying \term{types}. Edges can be classified as \term{homogeneous} when connecting nodes within the same type or \term{heterogeneous} when linking nodes of different types. This classification enables the partitioning of the graph by node types, which is advantageous for machine learning applications.

\subsubsection{Property Graphs}
Property graphs augment the flexibility of graph structures by incorporating \term{property-value} pairs and assigning a \term{label} to both nodes and edges. Property graphs can be transformed to and from directed edge-labeled graphs without loss of information. Although both models are equivalent in terms of representational capacity, directed edge-labeled structures are characterized by a more minimalistic framework, whereas property graphs offer greater flexibility. 

\subsubsection{Additional Graph Data Models}
Extensions of traditional graph models include \term{complex nodes} or \term{hypernodes} that encapsulate edges or nested graphs. In contrast, \term{hypergraphs} define \term{complex edges} that connect more than two nodes simultaneously.

\subsection{Querying}\label{querying}
Several languages exist for the analysis of graph structures. Common elements of these languages include graph patterns, relational operators, and path expressions. For instance, RDF graphs~\cite{Harris2013SPARQL} can be queries using SPARQL. 

\subsubsection{Graph Patterns}
At the core of graph query languages are \term{(basic) graph patterns}, which are intrinsically linked to the graph framework. In the context of directed edge-labeled graphs, the fundamental components consist of nodes and edge labels. In property graphs, these components include identifiers, labels, properties, and values.

Terms are categorized into constants and variables. The evaluation of graph patterns involves generating mappings from variables to constants, ensuring that the graph pattern's image is contained within the graph.

\subsubsection{Complex Graph Patterns}
Graph patterns can convert an input graph into a result table given by the licit constants for the variables in the patterns. These tables may then be manipulated using relational algebra using the following operations:
\begin{itemize}
    \item Unary operations:
    \begin{itemize}
        \item \term{Projection ($\pi$)} to extract a subset of columns,
        \item \term{Selection ($\sigma$)} to extract a subset of rows,
        \item \term{Column renaming ($\rho$)}.
    \end{itemize}
    \item Binary operations:
    \begin{itemize}
        \item \term{Union ($\cup$)} to merge rows from two tables,
        \item \term{Difference (-)} to exclude rows from one table that are present in another,
        \item \term{Joins ($\bowtie$)} to merge rows from two tables based on a related column.
    \end{itemize}
\end{itemize}
Graph patterns can thus be articulated within a subset of relational algebra comprising $\pi$, $\sigma$, $\rho$, and $\bowtie$.

\subsubsection{Navigational Graph Patterns}
A distinguishing feature of graph query languages is the incorporation of \term{path expressions} within queries. A path expression $r$ serves as a regular expression that encompasses paths of arbitrary lengths, which can be articulated as a \term{regular path query} $(x,r,y)$. The recursive nature of regular path queries is established as follows: a base path expression $r$ is a constant edge label. If $r$ is a path expression, its inverse $r^-$ along with the Kleene star $r^*$ also qualify as path expressions. Furthermore, if $r_1$ and $r_2$ denote path expressions, their disjunction $r_1 \mid r_2$ and concatenation $r_1 \cdot r_2$ remain path expressions.

Evaluation semantics for regular path queries must account for loops, which may yield infinite matching expressions. Options for management include the return of the shortest paths or those devoid of repeated nodes and edges. Alternatively, it is possible to simply return pairs of nodes linked by a matching path without detailing the entire path.

\subsection{Schema}\label{schema-identity-context}
Henceforth, we refer to a \term{data graph} as a collection of data represented as nodes and edges using one of the models discussed in \Cref{data-graphs}. We refer to a \term{knowledge graph} as a data graph potentially enhanced with representations of schema, identity, ontologies and/or rules. These additional representations may be embedded in the data graph, or layered above it.

Modeling data as graphs enables the deferral or avoidance of explicit schema definitions. Schemas can delineate high-level structures or semantic elements, leading to the categorization of \term{semantic}, \term{validating}, and \term{emergent} schemas.

\subsubsection{Semantic Schema}\label{schema_semantic}
A \term{semantic schema} delineates the meanings of high-level terms (\term{vocabulary}) utilized within the graph, thereby facilitating inferential reasoning. Natural groupings of nodes may be classified as \term{classes}, with hierarchical relationships established where child classes are designated as \term{subclasses} of their respective parents.

Edge labels, also referred to as \term{properties}, may be systematically organized into hierarchies, with specific attributes serving as \term{sub-properties} of broader properties. The \term{domain} of properties indicate the properties of objects to which nodes are connected. Conversely, \term{range} specifies the properties of objects to which nodes are connected through the property.

The \textit{RDF Schema} (RDFS) standard~\cite{Brickley2014RDFSchema1.1} establishes definitions for subclasses, subattributes, domains, and ranges applicable to RDF graphs, presented in \Cref{tab:semanticSchemaFeatures}. 

Typically, semantic schemas are constructed for graph data that may be incomplete. The absence of a specific edge does not necessarily imply the nonexistence of the relationship in actuality. Such systems operate under the \term{Open World Assumption} (\term{OWA}), as opposed to the \term{Closed World Assumption} (\term{CWA}). The CWA asserts that what is not known is assumed false. Consequently, the introduction of an edge may challenge previous assumptions. In the case of OWA it is possible for a relation to exist without being described by the graph.

\input{figs/tabSemanticSchemaFeatures}

\subsubsection{Validating Schema}
In scenarios where graphs represent diverse and incomplete data, the OWA is deemed more appropriate. Nevertheless, circumstances may arise where it is imperative to establish that the data graph is "complete." Thus, a \term{validating schema} can be defined to enforce constraints upon the data graph and identify any violations. While semantic schemas primarily infer new data, validating schemas assess the integrity of existing data.

A prevalent methodology for the definition of a validating schema involves the utilization of \term{shapes}~\cite{Knublauch2017SHACL, LabraGayo2017ValidatingRDF, Prudhommeaux2014ShapeExpressions}. A shape \term{targets} specific nodes and specifies necessary \term{constraints}. The identification of the target may manifest in various forms, such as instances of a specific property, the domain or range of an attribute, or outcomes derived from a query. Constraints may impose restrictions on the quantity or types of values that attributes can assume. 

Validating and semantic schemas can function synergistically, with validation applicable to data graphs inclusive of inferred data.

\subsubsection{Emergent Schema}
While semantic and validating schemas necessitate explicit definitions and constraints, it is acknowledged that a data graph may inherently exhibit latent structures, which can be extracted through an \term{emergent schema}~\cite{Pham2015EmergenSchemaFromRDF} or a \term{graph summary}~\cite{Cebiric2019SummarizingSemanticGraphs, Liu2018GraphuSummarizationMethodsAndApplications, Spahiu2016ABSTAT}. A prevalent design in this regard is represented by quotient graphs, which partition nodes based on an equivalence relation while preserving structural properties of the graph. Merging the nodes within each partition into a singular node generates a quotient graph.

Each node in the quotient graph corresponds to a partition of the original nodes, where an edge $(X,Y)$ is in the quotient graph if there exist $x\in X$ and $y\in Y$ such that $(x,y)$ constitutes an edge within the data graph.

Although quotient graphs can be defined in various ways, it is imperative that they \term{simulate} its input graph. For all input nodes $x$ and quotient nodes $X$ such that $x\in X$, if $(x,y)$ is an edge in the data graph, then a corresponding edge $(X,Y)$ must exist in the quotient graph with $y\in Y$. A more stringent condition, \term{bisimilarity}, stipulates that if $(X,Y)$ is an edge in the quotient graph, then for every $x\in X$, there exists a $y\in Y$ such that $(x,y)$ exists within the data graph.
For each possible partition of the data graph nodes there exists a  corresponding quotient graph. Other forms of similar or bisimilar graphs may be articulated according to the (bi)simulation relations~\cite{Cebiric2019SummarizingSemanticGraphs}. Such methodologies condense the data graph into a more abstract topology. Nodes may be assigned labels that represent the cardinality of partitions or high-level labels, foregoing the necessity of retaining all node labels.

\subsection{Identity}\label{identity}
To mitigate ambiguity one can adopt globally unique identifiers, as well as the incorporation of external identity edges to disambiguate nodes.

Merging multiple knowledge graphs may introduce ambiguities, resulting in naming conflicts. \term{Persistent Identifiers} (PIDs) serve to uniquely identify entities (for instance, DOI for academic papers, ORCID for authors, ISBN for books). The RDF specification advocates for the use of Internationalized Resource Identifiers (IRIs) to differentiate between web pages and tangible objects~\cite{Hakala2010PIDs}.

While HTTP IRIs facilitate global identification, they do not inherently assure persistence. \term{Persistent URL} (PURL) services provide stable identifiers that redirect to current locations, thereby ensuring that references remain valid~\cite{BernersLee2006LinkedData}\cite{Heath2011LinkedData}.

Even with the utilization of IRIs, disparate knowledge graphs may employ different identifiers to refer to the same entity. To manage these cases the OWL standard for example encompasses the construct \texttt{owl:sameAs} to establish equivalence.
Identifiers may not convey semantic significance. For instance, Wikidata utilizes numerical IRIs to maintain language neutrality. RDF graphs typically include additional metadata such as labels, aliases, and comments. Multilingual lexicalized knowledge graphs further facilitate object recognition across different languages~\cite{DeMelo2015Lexvo.org, MartinezRodriguez2020InformationExtractionMeetsSemanticWeb}.  

In certain instances, graphs must represent unidentified objects using existential nodes (or blank nodes within RDF). Techniques such as skolemization may be employed to assign canonical labels, though some scholars advocate minimizing their application~\cite{Cyganiak2014rdf, Hogan2017CanonicalFormsIsomorphicEquivalentRDFGraphs, Longley2019RDFDatasetNormalization}.

\section{Deductive Information}\label{deductive-information}
The capacity for humans to infer additional information from a data graph transcends the explicit relationships denoted by edges. By utilizing data as foundational premises alongside some a priori general rules about the world, new data can be deduced. Such rules are classified as ``commonsense information''~\cite{McCarthy1990FomalizingCommonsense} or ``domain information''.

For machines to perform analogous deductions, formal instructions are required. Entailment regimes are employed to normalize conclusions that logically follow from initial premises. The ability to make these deductions enhances query response accuracy, classification, and inconsistency detection.

Although we have already discussed in \Cref{schema_semantic} how semantic schemas can capture subclass relations, we now discuss how more complex entailments can be captured and automated. Though one could leverage logical frameworks like First-Order Logic, we focus on ontologies which represent knowledge on data structured as a graph.

\subsection{Ontologies}\label{ontologies}
For successful entailment, precision concerning the meanings of terms is imperative. Since there is no ``correct'' meaning for a given term we may, its definition is a matter of convention.

The term ``ontology'' originates from philosophical discourse regarding the nature of existence. In the computing context, an \term{ontology} indicates a concrete, formal representation of the meanings attributed to terms within a specified domain.

The practical utility of an ontology is contingent upon consensus, detail, and adoption. Widespread adoption fosters consistent terminology and modeling practices, while agreement promotes interoperability.

Widely recognized ontology languages encompass the \textit{Web Ontology Language} (\textit{OWL})~\cite{Hitzler2014OWLPrimer} and the \textit{Open Biomedical Ontologies Format} (\textit{OBOF})~\cite{Mungall2012OBOF}.

\subsubsection{Interpretation}
It is possible to interpret a node or edge as corresponding to a tangible object or relation. The data graph can be conceptualized as a \term{domain graph}. The interpretation process entails mapping nodes and edges from the data graph to entities and relations within the domain graph. An \term{interpretation} is characterized by a domain graph and a mapping function that aligns the data graph to the domain graph. The domain graph adheres to the same modeling principles as the data graph. Under the Open World Assumption (OWA) (recall from \Cref{schema_semantic}), if an edge does not exist between two nodes in the data graph, similarly it cannot exist in the domain graph, since what is not known is assumed to be false. Conversely, under the Open World Assumption (OWA), we cannot be certain that this relation does not exist as this could be part of some knowledge not (yet) described by the graph. 

These foundational assumptions delineate the validity of interpretations, and which interpretations \term{satisfy} a given data graph. Additional assumptions pertain to the uniqueness of terms. The \term{Unique Name Assumption} (\term{UNA}) forbids interpretations that map two distinct data terms to a singular domain term, while the \term{No Unique Name Assumption} (\term{NUNA}) permits such interpretations.
\term{Semantic conditions} define the criteria for valid interpretations of a graph. As an illustration, if $p$ is a subclass of $q$, one could enforce that if the tuple $(x,y,p)$ is present in the domain graph, then the edge $(x,y,q)$ must exist.

\section{Inductive Information}\label{inductive-information}
While deductive knowledge is characterised by precise logical consequences, inductive information concerns the process of generalizing patterns derived from observations to generate novel predictions. Then \term{inductive knowledge} includes both the models used to encode patterns, as well as the predictions made by those models.
A variety of inductive methodologies are applicable to knowledge graphs. Unsupervised techniques leverage graph analytics to identify communities or clusters, as well as to discern central nodes and edges. Knowledge graph embeddings utilize self-supervision to derive low-dimensional numerical representations. The graph structure itself can also be advantageous for supervised learning approaches. Symbolic learning techniques possess the ability to derive symbolic models – i.e., logical formulae in the form of rules or axioms – from graphs in a self-supervised fashion. A discussion of supervised learning techniques applicable to knowledge graphs is presented in the subsequent chapter.

\section{Biomedical Knowledge Graphs}\label{kgs:biomed}
In biomedical research, traditional databases fail to capture the intricate relationships within molecular interactions, pharmacological properties, and clinical records~\cite{Callahan2020KBDS}\cite{Su2020NetworkEmbeddingBiomedicalbDS}. \term{Biological knowledge graphs} (\term{BKG}) overcome these limitations by structuring heterogeneous data like molecular interactions, pharmacological datasets, and clinical records, and facilitating tasks like disease modeling and personalized medicine or drug discovery~\cite{Lu2025BiomedicalKG}. We shortly review BKGs, categorizing them into domains, discussing key tasks, and  highlighting real-world applications.

Despite their transformative potential, BKGs face challenges related to data integration, scalability, and interpretability. The heterogeneous nature of biomedical data, inconsistencies in terminology, and the exponential growth of biomedical knowledge make it difficult to maintain accurate and up-to-date BKGs. Scalability remains a concern, particularly in processing large-scale networks and executing complex queries efficiently. Moreover, interpretability issues persist, as users often struggle to navigate intricate network structures and understand the reasoning behind AI-driven predictions.

\subsection{Domains}
Biomedical knowledge graphs (BKGs) serve as structured frameworks that integrate and analyze complex biomedical data across multiple domains. These domains encapsulate diverse sources of knowledge, each contributing to the construction and application of BKGs in distinct yet interconnected ways. We list three primary domains, and for each we reference some BKG examples:
\begin{description}
    \item[Multi-omics] focusing on genomic~\cite{Jha2019genomicsKG}, transcriptomic~\cite{CavalleriEmanuele2024Aokg}, and proteomic~\cite{Zhang2022ontoprotein} data, supporting research in disease mechanisms and biological pathways.
    \item[Pharmacology] are instrumental in modeling interactions like drug-disease and drug-target~\cite{Gonzalez2023drugmechdb}, predicting adverse drug reactions, and facilitating drug repurposing efforts~\cite{Huang2024foundationModelDrugRepurposing}.
    \item[Medical knowledge] integrating electronic health records~\cite{Shang2021ehr} and clinical knowledge to improve diagnosis, treatment recommendations, and healthcare decision-making. Some disease specific BKGs stand out for conditions like hepatocellular carcinoma~\cite{Li2020kghc} or COVID-19~\cite{Zheng2021multiModalKGCOVID19}.
\end{description}
Some BKGs span multiple domains, creating comprehensive frameworks that enable cross-disciplinary insights.

\subsection{Tasks \& applications}
Beyond their structural aspects, BKGs enable four key tasks: 
\begin{description}
    \item[Knowledge management] involves structuring raw biomedical data~\cite{Percha2018globalNetworkBiomedicalRelationshipsDerivedText}\cite{Sang2018sematyp}, transforming disparate datasets into standardized formats, and integrating multiple sources into a unified framework~\cite{Himmelstein2017Hetionet}.
    \item[Knowledge retrieval] leverages BKGs to enhance data visualization, statistical analysis, and knowledge enhancement though query-based information retrieval~\cite{Pan2024unifyingLLMsKGs}\cite{Soman2024biomedicalKGOptimizedPromptGenerationForLLMs}, allowing researchers and clinicians to quickly access relevant biomedical insights.
    \item[Knowledge reasoning] encompasses inference and prediction, enabling the discovery of novel relationships, such as identifying potential drug candidates~\cite{Huang2024foundationModelDrugRepurposing} or predicting disease-drug links~\cite{li2022graphrepresentationlearningbiomedicine}.
    \item[Knowledge interpretation] ensures the reliability of these predictions by tracing the reasoning process through logical explanations (e.g ~\cite{Jimenez2024explainableDrugRepurposing} visualises reasoning paths for drug repurposing) or assisted interpretation using AI-driven systems~\cite{ONeil2024phenomicsAssistant}.
\end{description}

The applications of BKGs extend across multiple biomedical fields. In clinical decision support, BKGs assist in diagnosing diseases, predicting health risks~\cite{Tao2020miningHealthKnowledgeHealthRiskPrediction}, and recommending personalized treatments. In drug discovery, they play a crucial role in identifying potential drug candidates, repurposing existing medications (like for COVID-19 ~\cite{Zhang2021drugRepurposingForCovid19}), and predicting adverse drug reactions~\cite{Abdelaziz2017largeScaleMiningKGDrugDrugInteractions}. Additionally, BKGs support scientific research by facilitating hypothesis generation and uncovering new research opportunities. They also enhance intelligent question-answering systems, helping to improve the accuracy and reliability of AI-driven medical chatbots~\cite{Shu2024KG-LLM}\cite{Sung2021canLMBeKnowledgeBases} and literature retrieval tools.

