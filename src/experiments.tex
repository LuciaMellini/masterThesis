\chapter{Experiments}
We now engage in our contribution to tackling the issue of automatic differential diagnosis of Mendelian diseases. In this context, we have developed a customized knowledge graph (KG) integrated with patient data, which we detail in \Cref{sec:patientKG}. Furthermore, in \Cref{sec:linkPredictionDiffDiagnosis} we outline the methodology by which we have reformulated our problem as a link prediction task, and how we have gone about the outlined approach in practice. We place an emphasis on demonstrating the validity of our selection of hyperbolic graph representation learning techniques (\Cref{sec:hypPatientKG}).

\section{Patient KG}\label{sec:patientKG}
In this section, we delineate the data selected for the purpose of differential diagnosis of Mendelian diseases. We proceed with an exploration of the underlying biomedical knowledge graph we have utilized and the chosen patient data. Additionally, we describe how these data sources have been integrated into a singular knowledge graph.

\subsection{Underlying biomedical KG}\label{sec:underlyingKG}
For what concerns the biomedical knowledge aspect, initially we considered PrimeKG \cite{chandak2023PrimeKG}, a knowledge graph aimed at precision medicine analyses that aggregates 20 high-quality resources. Unfortunately, at the time of use, we encountered significant shortcomings regarding the representation of Mendelian diseases. Drawing inspiration from the entities represented in PrimeKG, we constructed a customized knowledge graph. We have resorted to \emph{PheKnowLator} (\emph{Phenotype Knowledge Translator})~\cite{callahan2020PheKnowlator}\footnote{The Python library is accessible at \url{https://github.com/callahantiff/PheKnowLator}}, a KG framework designed for optimized construction of semantically rich, large-scale biomedical KGs that accommodates various standardized terminologies or vocabularies. To build our heterogeneous graph, we selected various ontologies, taking into account our final objectives and memory constraints. The chosen ontologies, categorized by resulting node types, are outlined below.


\paragraph{Gene Ontology}
\begin{itemize}
\item Gene Ontology Chemical Entities (GOCHE)
\item Gene Ontology (GO)
\end{itemize}

\paragraph{Genomic Features}
\begin{itemize}
\item Ontology of Genes and Genomes (OGG)
\item Sequence Ontology (SO)
\end{itemize}

\paragraph{Proteins}
\begin{itemize}
\item Protein Ontology (PR)
\item Cell Ontology (CL)
\item Human Phenotype Ontology (HP)
\item Molecular Function (MF)
\end{itemize}
\bigskip

\paragraph{Diseases}
\begin{itemize}
\item Disease Ontology (DOID)
\item Mondo Disease Ontology (MONDO)
\end{itemize}
\bigskip

\paragraph{Phenotypes}
\begin{itemize}
\item Human Phenotype Ontology (HP)
\item Phenotype And Trait Ontology (PATO)
\item uPheno Ontology (UPHENO)
\end{itemize}

The relations between the entities and their predicates derive from the annotations specified in the ontologies.

\input{figs/tabKGNodeTypes}
\input{figs/tabKGEdgeDistrib}
\input{figs/figKG_hypergraph}
In terms of magnitude, the knowledge graph comprises a total of $2.34\cdot10^5$ heterogeneous nodes and $2.71\cdot10^7$ heterogeneous edges. The graph contains a total of five node types and 117 edge predicates. In \Cref{fig:kg_hypergraph}, we show the hypergraph representation of the knowledge graph obtained by aggregating the ontological data sources. To simplify the representation, we specified edge predicates with a minimum of $10^5$ occurrences across the entire knowledge graph. The number of nodes of each type is provided in \Cref{tab:nodetypes}, alongside the distribution of (the most frequent) edge predicates among the node types, as shown in \Cref{tab:edgedistrib}.
\input{figs/figSubclassofTree}
\paragraph{Abstract Graph Structure}\label{sec:abstractGraphStructure}
It is evident that the graph is connected, with certain edge predicates being mutually symmetric, e.g., \emph{Has phenotype} and \emph{Phenotype of}. For each of the node types, edges of the predicate \emph{Subclassof} denote hierarchical relationships between the entities. In \Cref{fig:SubclassofTree}, we illustrate a subtree representing one of these hierarchical components in the knowledge graph. For further examples, we suggest exploring the tree representations provided by the EMBL-EBI Ontology Lookup Service\footnote{Visit the EMBL-EBI Ontology Lookup Service at the link \url{https://www.ebi.ac.uk/ols4/}.}. One may visualize the knowledge graph as comprising ``vertical'' components, one for each node type, akin to the example presented. In our discourse, we will refer to these subtrees as \term{hierarchical components}. These hierarchies are interconnected by ``horizontal'' links, which are indifferent to the hierarchical level of the nodes to which they pertain. This characteristic has led us to consider approaches based on hyperbolic geometry, as will be explored in \Cref{sec:hypPatientKG}.

\subsection{Patient data}
We have selected the patient data from the Phenopacket Store compiled by~\cite{Danis2025Phenopackets}, which is accessible at the dedicated repository~\cite{Robinson2024PhenopacketStore}. Our analyses are based on the most recent release to date, dated 19 January 2025 (version 0.1.24)\footnote{The phenopackets can be downloaded at \url{https://github.com/monarch-initiative/phenopacket-store/releases/download/0.1.24/all_phenopackets.zip}}, comprising 7799 cohorts.

The cohorts that represent individuals with Mendelian diseases adhere to the GA4GH Phenopacket Schema~\cite{jacobsen2022ga4ghPhenopacketSchema}\footnote{Comprehensive documentation can be found at \url{https://phenopacket-schema.readthedocs.io/en/latest/}}. The Phenopacket Schema represents an open standard for sharing disease and phenotype information, beneficial for both rare and common disease research. A Phenopacket integrates detailed phenotype descriptors with disease, patient, and genetic information, enabling the understanding of human diseases and biological phenomena.

For the patients collected in the Phenopacket Store, the following attributes are available:
\begin{itemize}
  \item patient code,
  \item sex,
  \item age at last encounter,
  \item phenotypes, with optional specification of the year of onset,
  \item diagnosed disease, with optional specification of the year of onset and genomic interpretations,
  \item reference to the research article.
\end{itemize}

We opted to focus on features that are consistently present in all cohorts or described with a similar level of detail. Consequently, we excluded the year of onset for individual phenotypes and the onset of the disease. Furthermore, noting that genomic interpretations are not always included, this aspect will be addressed through the links in the underlying knowledge graph described in the preceding section. We also removed the age of last encounter of the patient, as it is frequently unrelated to the diagnosed disease.

Given the inherent limitations of patient data regarding Mendelian diseases, we acknowledge that the dataset comprises a considerable number of diseases for which the number of cohorts is markedly low. To characterize the distribution of the Mendelian diseases available to us, we present in \Cref{fig:disease-histogram} a plot of occurrences for each disease in the Phenopacket Store, arranged in descending order.
\input{figs/plotMendDiseaseDistrib}

\subsection{Data integration}
The patient data has been integrated with the underlying knowledge graph by adding nodes of type \emph{Person} and \emph{Article}. Specifically, the \emph{Person} nodes encompass the actual patients, alongside two nodes representing male and female sexes, respectively. For standardization purposes, the \emph{Male} and \emph{Female} nodes are identified using the following IRIs: \texttt{$\langle$http://purl.obolibrary.org/obo/NCIT\_C16576$\rangle$} and \texttt{$\langle$http://purl.obolibrary.org/obo/NCIT\_C20197$\rangle$}. Each article is refered to by \\ \texttt{$\langle$https://pubmed.ncbi.nlm.nih.gov/{article\_id}$\rangle$}. The nodes pertaining to patients extend the \emph{Article} identifiers by appending the patient code, resulting in a string of the form \\ \texttt{$\langle$https://pubmed.ncbi.nlm.nih.gov/{article\_id}?{patient\_code}$\rangle$}. 

We clarify the integration of the Phenopacket data with the underlying knowledge graph in \Cref{fig:patient_kg_hypergraph}, which specifies how the additional nodes have been interconnected with one another and with the existing \emph{Phenotype} and \emph{Disease} nodes. Henceforth, we will refer to the integrated knowledge graph as \emph{PatientKG}.
\input{figs/figpatientKG_hypergraph}

\section{Link prediction for differential diagnosis}\label{sec:linkPredictionDiffDiagnosis}
In this section, we describe how we have employed PatientKG to address the challenge of differential diagnosis. After reframing our problem as to PatientKG, we discuss the experimental setup. In addition, we detail how we have managed working with a large graph. Most importantly we tie the methods analyzed in \Cref{grl,hyperbolic,hrl} to the specific characteristics of PatientKG.

\subsection{Experimental setup}\label{sec:expsetup}
Utilizing PatientKG, the problem of differential diagnosis is reframed as the link prediction task involving edges of type \emph{Has disease} connecting the \emph{Person} nodes representing patients to the corresponding \emph{Disease} node. Considering the techniques evaluated in \Cref{grl}, we have chosen an inductive approach, specifically Graph Neural Networks (GNNs), to enable the model to generalize to previously unseen patients. In particular, we have selected the HGCN model, according to the reasoning discussed in \Cref{sec:hypPatientKG}.

To train the model for link prediction and evaluate its performance, the edges in PatientKG were partitioned into two sets: a test set composed of randomly selected \emph{Has disease} edges and a training set comprising the remaining \emph{Has disease} edges and all other edges in PatientKG. To regulate the learning process through early stopping, we also have extracted a validation set.

The distribution of cohorts by disease, illustrated in \Cref{fig:disease-histogram}, indicates that approximately half of the diseases represented in the Phenopacket Store have fewer than 10 cohorts, and roughly one-third have at most 5 occurrences. Given the limited availability of annotated disease diagnoses, the test set only comprises diseases with at least 5 cohorts. In addition, we opted to not include \emph{Has disease} edges within the validation set utilized to monitor the learning process.

Since the test edges are derived from the relations provided by the Phenopacket Store, the model trained on the training set was evaluated on differential diagnoses exclusively among Mendelian diseases. This approach is logical as Mendelian diseases are often explored after all alternative common diagnoses have been ruled out. Preliminary experiments conducted using this data split revealed indications of potential overfitting. Since the articles typically pertain to specific diseases, the edges connecting patients to their corresponding articles of origin create a shortcut for inferring the patients' diseases. To prevent data leakage, we excluded all \emph{Has part} and \emph{Part of} edges linking the \emph{Person} nodes to the \emph{Article} nodes.

\medskip

\subsubsection{Hyperparameters}

In \cref{tab:hyperparams} we list how the main hyperparameters have been set across all experiments. The first three are related to the HGCN model:
\begin{itemize}
  \item the number of layers $L$,
  \item the number of attention heads $R$,
  \item the activation function $\sigma$.
\end{itemize}
The remaining values refer to the chosen optimizer and the training procedure.

The parameters for the Fermi-Dirac decoder are set to \texttt{r}=2 and \texttt{t}=1 (refer to \Cref{sec:linkPredictionHGCN}). These values were established based on hyperparameters recommended in the code repository provided by Hazy Research, which encompasses implementations of HGCN and other Euclidean and hyperbolic GNN models\footnote{We have utilized the implementations offered by the Hazy Research group at \url{https://github.com/HazyResearch/hgcn}. In particular, we have relied on their code for the shallow Poincaré ball embeddings, GCN, GAT models, and, of course, HGCN.}. 

\subsubsection{Negative sampling}
To make training more robust we applied negative sampling to generate pairs of nodes that are not connected in PatientKG. This is essential to allow the model to learn to recognize non-existent links as negative examples. In practice we have employed the \texttt{batched\_negative\_sampling} method from \texttt{torch-geometric.utils}\footnote{Documentation found at \url{https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html\#torch\_geometric.utils.batched\_negative\_sampling}}~\cite{fey2019pytorchGeometric}. For simplicity the non existent edges have been sampled uniformly at random among all possible edges in the complement graph. Most likely, the large amount of negative samples provides more information to the model about the graph, so we expect results to be more stable.

\subsubsection{Performance metrics}\label{sec:performanceMetrics}
The evaluation of the predictions is expressed as the cross-entropy loss with negative sampling (\Cref{sec:crossEntropyLossNegSampling}). 

We also report the area under the ROC (\emph{ROC-AUC}), as a way of measuring how well a binary classifier can tell two classes apart. The ROC curve itself shows the trade-off between the true positive rate $\left(\frac{TP}{TP+FN}\right)$ and the false positive rate $\left(\frac{FP}{FP+TN}\right)$, as you vary the decision threshold. The area under this curve sums up the model's overall ability to discriminate between classes. A score of 10 means perfect separation, while a score of 0.5 means the model is no better than random guessing. In general, the closer the value is to 1, the more effective the model is at distinguishing between the two categories.

Moreover, the average precision (\emph{AP}) score summarizes a precision-recall curve, that shows the trade-off between precision $\left(\frac{TP}{TP+FP}\right)$ and recall $\left(\frac{TP}{TP+FN}\right)$ for different thresholds. The average precision is computed as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight:
\begin{equation*}
  \text{AP} = \sum_n (R_n - R_{n-1}) P_n
\end{equation*} 
where $P_n$ and $R_n$ are the precision and recall at the $n$th threshold.
This metric is useful since it is robust against class imbalance. In our case the positive class—actual edges connecting patients and diseases—is much smaller than the negative class.

\subsection{Managing a large graph}
As seen in the description of the HGCN architecture, the aggregation step (\Cref{sec:hgcnAggregation}) requires the model to access the neighbourhoods of each node. In the code implemented in the Hazy Research repository this information is provided in the form of an adjacency matrix of the whole input graph. However for large graphs like PatientKG, this approach is not feasible due to memory constraints, especially considering that the model is trained and evaluated on GPU.
Seen these limitations it was necessary to settle for the more general global version of the aggregation step. 
To further overcome this issue we have initially attempted to reimplement the model using sparse matrices, keeping in mind the properties of PatientKG's adjacency matrix. Unfortunately we encountered various technical issues since the \texttt{PyTorch} library used to implement HGCN is ill equipped to handle sparse tensors. The attempted solution entailed specifying methods, among others, for sparse-sparse and sparse-dense matrix division, row-wise normalization, and various hyperbolic functions, such as the hyperbolic tangent. However, accounting for forward and backward passes, we were unable to achieve a working implementation considering the time constraints and scope of this thesis.

We then opted for a more straightforward solution, that is to use mini-batching of the graph. We now discuss the validity of this choice and how we have implemented this approach in our experiments.

\subsubsection{Mini-batching}

Training deep neural networks (DNNs) typically involves processing independent and identically distributed (i.i.d.) examples, whereas graph neural networks (GNNs) operate on interconnected vertices within a graph structure, introducing dependencies that complicate training. GNNs can be trained using either full-graph (full-batch) or mini-batch approaches~\cite{bajaj2024graph}.

In full-graph training, message-passing is performed across the entire graph in each epoch, ensuring that all vertex dependencies are considered. However, this method becomes computationally expensive and memory-intensive for large graphs, requiring multi-GPU model parallelism where the graph is partitioned and hidden features are exchanged across GPUs. While full-graph training avoids information loss by processing the complete graph, its high per-epoch cost and communication overhead make scaling difficult.

Mini-batch training, in contrast, splits the graph into smaller subgraphs (batches) and processes them iteratively, updating model parameters multiple times per epoch. However, preparing these mini-batches is non-trivial because GNNs require $k$-hop neighbourhood aggregation—meaning that for a GNN with $L$ layers, each batch must include vertices up to $L$ hops away to ensure correct message-passing. This leads to the neighbourhood explosion problem, where the required subgraph grows exponentially with depth, making full neighbourhood aggregation impractical. To mitigate this, mini-batch systems use sampling techniques (e.g., Neighbourhood Sampling, ClusterGCN, GraphSAINT) to load only a subset of the k-hop neighbours, trading off some accuracy for efficiency. 

Despite these challenges, mini-batch training often converges faster in practice because it performs multiple parameter updates per epoch, whereas full-graph training updates only once per epoch. Also the simple Neighbourhood Sampling method empirically shows a more stable behaviour.

To implement the batching of PatientKG into subgraphs we have relied on the \texttt{torch-geometric} library~\cite{fey2019pytorchGeometric}. More specifically we have chosen to sample the subgraphs using the \texttt{NeighborSampler} class\footnote{Documentation found at \url{https://pytorch-geometric.readthedocs.io/en/latest/modules/sampler.html\#torch\_geometric.sampler.NeighborSampler}}. This class is designed to sample a fixed-size batch of so called seed nodes, and for each of these it samples their neighbourhood. For each seed node one can specify a list of integers $[n_1, n_2, \dots, n_k]$, such that $n_1$ of its neighbours are sampled, then from each of those 1-hop neighbours $n_2$ neighbours are sampled, and so on, until $n_k$ neighbours are sampled from the $k$-th hop neighbours. The sampling is performed in a breadth-first manner, meaning that all nodes at the first hop are sampled before moving to the second hop, and so on. This approach allows us to control the size and the of the subgraphs sampled, letting us determine the size of the input adjacency matrix a priori. This sampling strategy implies that all the nodes are seen at least once by the model when they are seed nodes of a given batch, and can be re-extracted if they are selected among the sampled neighbours of other nodes. 

Like when batching in classical machine learning settings, on each local sample the forward and backward passes are performed independently, and the weights of the model are updated after each batch. The weights are updated according to the loss value computed on only the seed nodes in each batch. Empirically, we have found that computing the loss over all batch nodes to guide backpropagation causes overfitting. Focusing on seed nodes prevents the backpropagation signal from being diluted across thousands of neighbours. This choice allows the model to learn more effectively from the most relevant nodes in each batch, while still benefiting from the rich information provided by their neighbors.

To assure the compatibility among batches it was necessary to set the curvature of the hyperbolic space to a fixed value, which we have set to $c=1$. This derives from the definition of the Poincaré ball model (\Cref{sec:poincareBall}).

\medskip 

In addition to the hyperparameters listed in \Cref{tab:hyperparams}, we also have set the batch size and neighbourhood sample sizes. Using the parameters in GraphSAGE~\cite{Hamilton2017inductiveRepresentationLearning}, we set the neighbourhood sample sizes to $n_1=25$ and $n_2=10$ since we were working with a 2 layer model. To respect memory constraints we have set the batch size to $172$. In addition we have tested the model on batches formed by fewer extracted nodes, but with additional hops from the seed nodes. Concretely the list describing the neighbourhood sample sizes was set to $[5,3,3,3]$. In this case we were able to increase the batch size to $235$ nodes.

\subsubsection{Final inference step}
Recall from \Cref{sec:hgcnArchitecture} that the link prediction task requires the encoded embeddings to be decoded to compute the probability scores among the edges. Note that when encoding a subgraph the resulting embeddings refer only to that subset of nodes. This does not pose a problem during training seen that the embeddings local to the batch are sufficient to compute the local loss for the backward pass. In the case of validation and testing, however, one needs the embeddings of all the nodes to compute the link prediction scores. To address this, one adds a final inference step after training. This involves running a forward pass on (ideally) the entire graph. As discussed before, for PatientKG this is not feasible due to memory constraints, therefore one can load the full graph in manageable chunks, made up of some seed nodes and their whole neighbourhoods. In this way the forward pass is as similar as possible to the full-graph inference. 
\input{figs/plotNeighDistr}
In \Cref{fig:neighDistr} we plot the distribution of the neighbourhood sizes among nodes in PatientKG. The distribution is highly skewed, as put in evidence by the knee point in the plot\footnote{The knee point has been located using the kneedle algorithm~\cite{satopaa2011KneePointDetection}}. This has allowed us to reduce the memory footprint during inference by creating batches mad up of few large neighbourhood nodes and a lot of small neighbourhood nodes. 

\medskip
To wrap things up, we summarize the experimental procedure in algorithm \ref{alg:exp}.
\input{figs/algExp}




\subsection{Why hyperbolic graph representation learning?}\label{sec:hypPatientKG}

\input{figs/tabSubclassofPerfHyp.tex}
Prior to delving into the run experiments, we would like to account for the selection of hyperbolic graph representation learning techniques, specifically HGCN. As discussed in \Cref{sec:hyperbolicAndTrees}, hyperbolic geometry is particularly suited to represent hierarchical structures, such as those nested within PatientKG (refer to \Cref{sec:abstractGraphStructure}). To empirically verify this, we embedded each hierarchical component into hyperbolic space. To emphasize the positioning of each node within the hierarchy, we have considered the transitive closure of each subtree. The transitive closure of a directed graph is derived by adding an edge between every pair of nodes that are connected by a directed path. For instance, \Cref{fig:diseasePoincare} depicts the embedded \emph{Disease} nodes arranged within a Poincaré ball. One notices that nodes with a more extensive neighbourhood, i.e. nodes situated higher in the ontological hierarchy, are positioned closer to the centre of the ball. This representation can be interpreted as a real-world instance of the structure schematized in \Cref{fig:radialTree}, in accordance with the considerations articulated in \Cref{sec:expGrowth}. 
\input{figs/figDiseasePoincare.tex}

Although the shallow embedding has yielded favorable results, we opted for an inductive graph representation technique, as touched on in the previous section. To ensure that the HGCN model would capture the hierarchical components within PatientKG, we assessed the model's performance exclusively on these subgraphs. In comparison, we conducted the same experiments using two representatives of advanced Euclidean GNN models, namely GCN (\Cref{sec:GCN}) and GAT (\Cref{sec:neighbourhoodAttention}). The hyperparameters employed in our experiments are detailed in Table~\ref{tab:hyperparams}; the number of attention heads is overlooked by the GCN model. 

\subsubsection{Performance on hierarchical components}

In \Cref{tab:tabSubclassofPerf}, we display the performance of the three models resulting from a random split of the edges into training, validation, and test sets, with validation and test sets containing 10\% of the edges each. For each edge we have produced one negative sample. We conducted a series of experiments while varying the desired embedding size. 

As anticipated, performance improves upon increasing length of the hidden representation of the nodes. The results distinctly illustrate that HGCN surpasses Euclidean GNN models. The sole exception is observed within the \emph{Genomic feature} hierarchical component, where GCN and GAT yield slightly superior performance compared to HGCN at larger embedding sizes. In such instances, the loss remains elevated, suggesting that the models may be making incorrect predictions confidently. These tests confirm our confidence in employing HGCN for the link prediction task within PatientKG.
\input{figs/tabSubclassofPerf.tex}

We are aware of more advanced techniques than HGCN that are tailored to knowledge graph applications. In particular, we highlight the \textsc{Att\_H} model~\cite{chami2020lowDimensionalHyperbolicKnowledgeGraphEmbeddings}, proposed by the authors of HGCN. Their rationale is that existing hyperbolic embedding methods do not adequately account for the logical patterns present in knowledge graphs, which we have referred to as "horizontal" links. Consequently, they introduce a class of hyperbolic KG embedding models that simultaneously capture hierarchical and logical patterns by combining hyperbolic reflections and rotations with attention. We have chosen to stick with a model like HGCN that emphasizes the hierarchical components, as we were interested in evaluating whether this approach would be sufficient to address the challenges of differential diagnosis. We leave the exploration of more advanced hyperbolic models for future work.



\section{Performance for differential diagnosis}
We now dive into the performance of the HGCN model trained according to the experimental setup described in \Cref{sec:expsetup}. In \Cref{fig:results} we show how the metrics have evolved across training epochs, for both training and validation sets. 

Recall that in the case of the loss we are aiming for higher values, whilst for ROC-AUC and AP we are aiming for values close to 1. From all the graphs we see that the model is overfitting, as the performance on the training set is significantly better than that on the validation set. Also, across the epochs the performance remains stable on average, so we can conclude that the model is not learning from the data in PatientKG. The fact the ROC-AUC is close to 0.5 and the AP is close to 0, confirms that the model has failed completely to learn anything useful. One could argue that the predictions are worse than random, in the sense that it is labeling almost everything as negative. This interpretation is supported buy the fact that the addition of negative samples makes the average precision score even lower. 

As an additional remark, in the case of the loss and ROC-AUC metrics, the evolution for both 20:1 and 50:1 negative sampling ratios is essentially identical. This is happening since the seed has been set to the same value across both experiments. Since the model is not learning from the data, it is not finding useful gradients from the data, so the training trajectory is dictated almost entirely by the optimizer dynamics. This explains why metrics simply follow the noise-level behaviour due to the steps brought out by the optimizer.

\medskip

Turning to the performance results when evaluating the model on the test set, we report the results in \Cref{tab:test_results}. Even tough we take into consideration only the \emph{Has disease} links, the results are consistent with those observed on various predicates during training and validation. The loss remains high, while both ROC-AUC and AP scores are close to random guessing. Also, the considerations on the effect of negative sampling hold true here as well.

\begin{table}[ht]
  \centering
  \caption{Test set results}
  \begin{tabular}{@{}r|ccc@{}}
    \toprule
    negative samples & \emph{Loss} & \emph{ROC-AUC} & \emph{AP score} \\ 
    \midrule
    20:1 & 1.5388 & 0.3812 & 0.0146 \\ 
    50:1 & 1.5365 & 0.3820 & 0.0098 \\ 
    \bottomrule
  \end{tabular}
  \label{tab:test_results}
\end{table}

\input{figs/results}
