\chapter{Knowledge Graphs}\label{kgs}
This chapter presents a comprehensive examination of knowledge graphs, elucidating their theoretical underpinnings and a range of applications. The discussion begins with a formal definition of knowledge graphs in Sections~\ref{definition}-~\ref{inductive-information}, followed by an exploration of their specific applications within the life sciences in Section~\ref{kgs:biomed}.

\section{Definition}\label{definition}
The concept of knowledge graphs has garnered significant attention since Google's introduction of its Knowledge Graph in 2012, particularly within the realm of Semantic Web research. However, despite their widespread utilization, a consensus on a singular definition remains elusive, as academic sources provide diverse interpretations. The following definitions exemplify this variation:

\begin{description}
    \item[Structural and compositional aspects] Knowledge graphs are characterized by graph-based representations of information. Paulheim~\cite{Paulheim2016KnowledgeGR} defines a knowledge graph as an entity-focused graph that (i) illustrates real-world entities alongside their interrelations, (ii) establishes classes and relations within a defined schema, (iii) facilitates the interrelation of arbitrary entities, and (iv) encompasses various topical domains. Echoing this, the Journal of Web Semantics~\cite{Kroetsch2016knowledge} characterizes knowledge graphs as comprised of entities, their types, and the relationships among those entities.
    
    \item[Domain-specific representations] According to the Semantic Web Company, knowledge graphs can adapt to represent structures specific to varied fields, encompassing concepts, documents, and datasets~\cite{Blumauer2014knowledge}.
    
    
        \item[Formal definition] FÃ¤rber et al.~\cite{Farber2016linked} articulate knowledge graphs as RDF graphs (introduced in Section~\ref{models:directed_edge_labeled_graphs}), which consist of a collection of $(s, p, o)$ triples, where:
    \begin{itemize}
        \item $s\in U \cup B$ denotes a subject,
        \item $o\in U\cup B\cup L$ denotes an object,
        \item $p\in U$ denotes a predicate
    \end{itemize}
    Here, an RDF term can be represented as a URI ($u\in U$), a blank node ($b\in B$), or a literal ($l\in L$).
    
    \item[Dynamic extraction] An emphasis on the automatic extraction of interconnected facts from the web has been presented by Pujara et al.~\cite{Pujara2013KGIdentification}.
\end{description}

The aforementioned diversity in definitions complicates discussions and comparative studies, emphasizing the need for a common definition. In response to this requirement, Ehrlinger et al.~\cite{Ehrlinger2016TowardsAD} propose the following definition for knowledge graphs:
\begin{center}
    \begin{quote}
        A knowledge graph acquires and integrates information into an ontology and applies a reasoner to derive new knowledge.
    \end{quote}
\end{center}
This definition contributes to a unified comprehension of knowledge graphs through three salient aspects:
\begin{description}
    \item[Data integration] Knowledge graphs gather and incorporate data from disparate sources, which renders them both dynamic and expandable.
    \item[Inference capabilities] The employment of reasoning engines facilitates the deduction of new information, thereby augmenting the functionality beyond that of static data repositories.
    \item[Ontological basis] The foundation of knowledge graphs rests on ontological structures, which provide a formal framework for the representation of knowledge and relationships.
\end{description}

Knowledge graphs exhibit a complexity that surpasses that of traditional databases or ontologies, combining the beneficial properties of both to enable automated reasoning and the dynamic incorporation of information. In this context, the functionality and capabilities of knowledge graphs are deemed to be of greater significance than their possible great size.

\section{Data Graphs}\label{data-graphs}
The foundational concept of knowledge graphs is based on the transformation of data into a graph structure, resulting in what is referred to as a \term{data graph}. This methodology confers enhanced flexibility in integrating new data sources when contrasted with relational models, which necessitate predefined schemas. Although tree structures offer analogous adaptability, graph structures do not impose hierarchical constraints and permit the existence of cycles. An exploration of the various graph-structured data models that can be employed to represent such graphs is provided in~\cite{Hogan2021KGs}.

Further formal details pertinent to the subsequent sections can be found in Appendix~\ref{app:data-graphs}.

\subsection{Models}\label{models}
The principal graph structures utilized to represent knowledge graphs are delineated in this section, progressively introducing increasingly complex models.

\subsubsection{Directed Edge-Labeled Graphs}\label{models:directed_edge_labeled_graphs}
A directed edge-labeled graph is composed of a set of nodes and a set of directed, labeled edges interconnecting these nodes. Within knowledge graphs, nodes correspond to entities, while edges represent the relationships between them. The Resource Description Framework (RDF)~\cite{Cyganiak2014rdf}, as endorsed by the World Wide Web Consortium (W3C)\footnote{More details about RDFs at \url{https://www.w3.org/TR/rdf12-concepts/}}, represents a standard data model. This model specifies node types including Internationalized Resource Identifiers (IRIs)\footnote{Section of the W3C working draft on RDFs regarding IRIs \url{https://www.w3.org/TR/rdf12-concepts/\#section-IRIs}} for global identification, literals for strings and datatype values, as well as blank nodes for anonymous nodes.

\subsubsection{Heterogeneous Graphs}
Heterogeneous graphs provide a generalization of directed edge-labeled graphs by permitting nodes and edges to possess varying \term{types}. Edges can be classified as \term{homogeneous} when connecting nodes within the same property or \term{heterogeneous} when linking nodes of different types. This classification enables the partitioning of the graph by node types, which is advantageous for machine learning applications.

\subsubsection{Property Graphs}
Property graphs augment the flexibility of graph structures by incorporating \term{property-value} pairs and assigning a \term{label} to both nodes and edges. Attribute graphs can be transformed to and from directed edge-labeled graphs without loss of information. Although both models are equivalent in terms of representational capacity, directed edge-labeled structures are characterized by a more minimalistic framework, whereas property graphs offer greater flexibility. The choice between these models is contingent upon practical considerations, such as the availability of implementations.

\subsubsection{Additional Graph Data Models}
Extensions of traditional graph models include \term{complex nodes} or \term{hypernodes} that encapsulate edges or nested graphs. In contrast, \term{hypergraphs} define \term{complex edges} that connect more than two nodes simultaneously.

\subsection{Querying}\label{querying}
Several languages exist for the analysis of graph structures. SPARQL is utilized for querying RDF graphs~\cite{Harris2013SPARQL}, while graph databases may employ query languages such as Cypher~\cite{Francis2018Cypher}, Gremlin~\cite{Rodriguez2015Gremlin}, and G-CORE~\cite{Angles2018G-CORE}~\cite{Angles2017FoundationmodernQueryLnguagesforGraphDatabases}. Common elements of these languages include graph patterns, relational operators, and path expressions.

\subsubsection{Graph Patterns}
At the core of graph query languages are \term{(basic) graph patterns}, which are intrinsically linked to the graph framework. In the context of directed edge-labeled graphs, the fundamental components consist of nodes and edge labels. In attribute graphs, these components include identifiers, tags, attributes, and values.

Terms are categorized into constants and variables. The evaluation of graph patterns involves generating mappings from variables to constants, ensuring that the graph pattern's image is contained within the graph.

The variables in the graph patterns could be mapped to the same constant terms; however, such instances may not always be desirable. The underlying semantics may include:
\begin{itemize}
    \item \term{Homomorphism-based semantics}, which permits multiple variables to map to identical components.
    \item \term{Isomorphic-based semantics}, which stipulates distinct mappings for nodes and edge variables.
\end{itemize}

\subsubsection{Complex Graph Patterns}
Graph patterns can convert an input graph into a result table, which may then be manipulated using relational algebra. The operations applicable include:
\begin{itemize}
    \item Unary operations:
    \begin{itemize}
        \item \term{Projection ($\pi$)} to extract a subset of columns,
        \item \term{Selection ($\sigma$)} to extract a subset of rows,
        \item \term{Column renaming ($\rho$)}.
    \end{itemize}
    \item Binary operations:
    \begin{itemize}
        \item \term{Union ($\cup$)} to merge rows from two tables,
        \item \term{Difference (-)} to exclude rows from one table that are present in another,
        \item \term{Joins ($\bowtie$)} to merge rows from two tables based on a related column.
    \end{itemize}
\end{itemize}
Graph patterns can thus be articulated within a subset of relational algebra comprising $\pi$, $\sigma$, $\rho$, and $\bowtie$.

\subsubsection{Navigational Graph Patterns}
A distinguishing feature of graph query languages is the incorporation of \term{path expressions} within queries. A path expression $r$ serves as a regular expression that encompasses paths of arbitrary lengths, which can be articulated as a \term{regular path query} $(x,r,y)$. The recursive nature of regular path queries is established as follows: a base path expression $r$ is a constant edge label. If $r$ is a path expression, its inverse $r^-$ along with the Kleene star $r^*$ also qualify as path expressions. Furthermore, if $r_1$ and $r_2$ denote path expressions, their disjunction $r_1 \mid r_2$ and concatenation $r_1 \cdot r_2$ remain path expressions.

Evaluation semantics for regular path queries must account for loops, which may yield infinite matching expressions. Options for management include the return of the shortest paths or those devoid of repeated nodes and edges. Alternatively, it is possible to return merely pairs of nodes linked by a matching path without detailing the entire path.

\section{Schema, identity, context}\label{schema-identity-context}
In this section we describe various enhancements and extensions of the data graph â relating to schema, identity and context â that provide additional structures for accumulating knowledge. Henceforth, we refer to a \term{data graph} as a collection of data represented as nodes and edges using one of the models discussed in~\ref{data-graphs}. We refer to a \term{knowledge graph} as a data graph potentially enhanced with representations of schema, identity, context, ontologies and/or rules. These additional representations may be embedded in the data graph, or layered above it.

Modeling data as graphs enables the deferral or circumvention of explicit schema definitions. Schemata can delineate high-level structures or semantic elements, leading to the categorization of \term{semantic}, \term{validating}, and \term{emergent} schemata.

\subsubsection{Semantic Schema}\label{schema_semantic}
A \term{semantic schema} delineates the meanings of high-level terms (\term{vocabulary}) utilized within the graph, thereby facilitating inferential reasoning. Natural groupings of nodes may be classified as \term{classes}, with hierarchical relationships established where child classes are designated as \term{subclasses} of their respective parents.

Edge labels, also referred to as \term{properties}, may be systematically organized into hierarchies, with specific attributes serving as \term{sub-properties} of broader properties. The \term{domain} of properties indicate the properties of objects to which nodes are connected. Conversely, \term{range} specifies the properties of objects to which nodes are connected through the property.

The \textit{RDF Schema} (RDFS) standard~\cite{Brickley2014RDFSchema1.1} establishes definitions for subclasses, subattributes, domains, and ranges applicable to RDF graphs. Semantic illustrations inherent to these features are presented in Table~\ref{tab:semanticSchemaFeatures}. The \textit{Web Ontology Language} (OWL) standard~\cite{Hitzler2014OWLPrimer} offers expanded definitions.

Typically, semantic schemas are constructed for graph data that may be incomplete. The absence of a specific edge does not necessarily imply the nonexistence of the relationship in actuality. Such systems operate under the \term{Open World Assumption} (\term{OWA}), as opposed to the \term{Closed World Assumption} (\term{CWA}). The CWA allows for definitive assertions regarding the existence of relationships. Consequently, the introduction of an edge may challenge previous assumptions, while the OWA maintains that a conclusively proved false statement remains false, despite the addition of further edges.

\input{figs/tabSemanticSchemaFeatures}

\subsubsection{Validating Schema}
In scenarios where graphs represent a broad spectrum of diverse and incomplete data, the OWA is deemed more appropriate. Nevertheless, circumstances may arise where it is imperative to establish that the data graph is "complete." Thus, a \term{validating schema} can be defined to enforce constraints upon the data graph and identify any violations. While semantic schemata primarily infer new data, validating schemata assess the integrity of existing data.

A prevalent methodology for the definition of a validating schema involves the utilization of \term{shapes}~\cite{Knublauch2017SHACL, LabraGayo2017ValidatingRDF, Prudhommeaux2014ShapeExpressions}. A shape \term{targets} specific nodes and specifies necessary \term{constraints}. The identification of the target may manifest in various forms, such as instances of a specific property, the domain or range of an attribute, or outcomes derived from a query. Constraints may impose restrictions on the quantity or types of values that attributes can assume. An \term{open shape} permits the inclusion of additional attributes, whereas a \term{closed shape} imposes stricter limitations.

Validating and semantic schemata can function synergistically, with validation applicable to data graphs inclusive of inferred data. Open shapes may be favored when enumerating constraints across all potential attributes.

\subsubsection{Emergent Schema}
While semantic and validating schemata necessitate explicit definitions and constraints, it is acknowledged that a data graph may inherently exhibit latent structures, which can be extracted through an \term{emergent schema}~\cite{Pham2015EmergenSchemaFromRDF} or a \term{graph summary}~\cite{Cebiric2019SummarizingSemanticGraphs, Liu2018GraphuSummarizationMethodsAndApplications, Spahiu2016ABSTAT}. A prevalent design in this regard is represented by quotient graphs, which partition nodes based on an equivalence relation while preserving structural properties of the graph. Merging the nodes within each partition into a singular node generates a quotient graph.

Each node in the quotient graph corresponds to a partition of the original nodes, with an edge $(X,Y)$ is in the quotient graph if there exist $x\in X$ and $y\in Y$ such that $(x,y)$ constitutes an edge within the data graph.

Although a quotient graphs can be defined in various ways, it is imperative that they \term{simulate} its input graph. For all input nodes $x$ and quotient nodes $X$ such that $x\in X$, if $(x,y)$ is an edge in the data graph, then a corresponding edge $(X,Y)$ must exist in the quotient graph with $y\in Y$. A more stringent condition, \term{bisimilarity}, stipulates that if $(X,Y)$ is an edge in the quotient graph, then for every $x\in X$, there exists a $y\in Y$ such that $(x,y)$ exists within the data graph. Formal definitions for these concepts are provided in Appendix~\ref{app:emergent-schema}.
For each possible partition of the data graph nodes there exists a  corresponding quotient graph. Other forms of similar or bisimilar graphs may be articulated according to the (bi)simulation relations~\cite{Cebiric2019SummarizingSemanticGraphs}. Such methodologies condense the data graph into a more abstract topology. Nodes may be assigned labels that represent the cardinality of partitions or high-level labels, foregoing the necessity of retaining all node labels.

\subsection{Identity}\label{identity}
To mitigate ambiguity one can adopt globally unique identifiers, as well as the incorporation of external identity edges to disambiguate nodes.

Merging multiple knowledge graphs may introduce ambiguities, resulting in naming conflicts. \term{Persistent Identifiers} (PIDs) serve to uniquely identify entities (for instance, DOI for academic papers, ORCID for authors, ISBN for books). The RDF specification advocates for the use of Internationalized Resource Identifiers (IRIs) to differentiate between web pages and tangible objects~\cite{Hakala2010PIDs}.

While HTTP IRIs facilitate global identification, they do not inherently assure persistence. \term{Persistent URL} (PURL) services provide stable identifiers that redirect to current locations, thereby ensuring that references remain valid~\cite{BernersLee2006LinkedData}\cite{Heath2011LinkedData}.

Even with the utilization of IRIs, disparate knowledge graphs may employ different identifiers to refer to the same entity. To manage these cases the OWL standard for exampleencompasses the construct \texttt{owl:sameAs} to establish equivalence.
Identifiers may not convey semantic significance. For instance, Wikidata utilizes numerical IRIs to maintain language neutrality. RDF graphs typically include additional metadata such as labels, aliases, and comments. Multilingual lexicalized knowledge graphs further facilitate object recognition across different languages~\cite{DeMelo2015Lexvo.org, MartinezRodriguez2020InformationExtractionMeetsSemanticWeb}.  

In certain instances, graphs must represent unidentified objects using existential nodes (or blank nodes within RDF). Techniques such as skolemization may be employed to assign canonical labels, though some scholars advocate minimizing their application~\cite{Cyganiak2014rdf, Hogan2017CanonicalFormsIsomorphicEquivalentRDFGraphs, Longley2019RDFDatasetNormalization}.

\section{Deductive Information}\label{deductive-information}
The capacity for humans to infer additional information from a data graph transcends the explicit relationships denoted by edges. By utilizing data as foundational premises alongside some a priori general rules about the world, new data can be deduced. Such rules are classified as ``commonsense information''~\cite{McCarthy1990FomalizingCommonsense} or ``domain information''.

For machines to perform analogous deductions, formal instructions are required. Entailment regimes are employed to normalize conclusions that logically follow from initial premises. The ability to make these deductions enhances query response accuracy, classification, and inconsistency detection.

Although we have already discussed in Section~\ref{schema_semantic} how semantic schemata can capture subclass relations, we now discuss how more complex entailments can be captured and automated. Though one could leverage logical frameworks like First-Order Logic, we focus on ontologies which constitute a formal representation of knowledge that, importantly for us, can be represented as a graph.

\subsection{Ontologies}\label{ontologies}
For successful entailment, precision concerning the meanings of terms is imperative. Since there is no ``correct'' meaning for a given term we may, its definition is a matter of convention.

The term ``ontology'' originates from philosophical discourse regarding the nature of existence. In the computing context, an \term{ontology} indicates a concrete, formal representation of the meanings attributed to terms within a specified domain.

The practical utility of an ontology is contingent upon consensus, detail, and adoption. Widespread adoption fosters consistent terminology and modeling practices, while agreement promotes interoperability.

Widely recognized ontology languages encompass the \textit{Web Ontology Language} (\textit{OWL})~\cite{Hitzler2014OWLPrimer} and the \textit{Open Biomedical Ontologies Format} (\textit{OBOF})~\cite{Mungall2012OBOF}.

\subsubsection{Interpretation}
It is possible to interpret a node or edge as corresponding to a tangible object or relation. The data graph can be conceptualized as a \term{domain graph}. The interpretation process entails mapping nodes and edges from the data graph to entities and relations within the domain graph. An \term{interpretation} is characterized by a domain graph and a mapping function that aligns the data graph to the domain graph. The domain graph adheres to the same modeling principles as the data graph. Under the Open World Assumption (OWA) (recall from Section~\ref{schema_semantic}), if an edge does not exist between two nodes in the data graph, similarly it cannot exist in the domain graph, since what is not known is assumed to be false. Conversely, under the Open World Assumption (OWA), we cannot be certain that this relation does not exist as this could be part of some knowledge not (yet) described by the graph. 

These foundational assumptions delineate the validity of interpretations, and which interpretations \term{satisfy} a given data graph. Additional assumptions pertain to the uniqueness of terms. The \term{Unique Name Assumption} (\term{UNA}) forbids interpretations that map two distinct data terms to a singular domain term, while the \term{No Unique Name Assumption} (\term{NUNA}) permits such interpretations.
\term{Semantic conditions} define the criteria for valid interpretations of a graph. As an illustration, if $p$ is a subclass of $q$, one could enforce that if the tuple $(x,y,p)$ is present in the domain graph, then the edge $(x,y,q)$ must exist.

\subsubsection{Model-Theoretic Semantics}
Interpretations that fulfill a graph's requirements are designated as \term{models}. Under the OWA, a model may accommodate more edges than those delineated in the data graph. To refine the constraints on models, the inclusion of \term{axioms} can enforce conditions that interpretations must achieve. Such axioms are presented similarly to the definitions outlined in Table~\ref{tab:semanticSchemaFeatures}.

\subsubsection{Entailment}
A graph \term{entails} another graph if every model consistent with the former is also a model of the latter. The latter graph conveys no additional information beyond what is contained within the former.

The determination of whether one graph entails another remains undecidable~\cite{Hitzler2010FoundationsSWTechnologies}\footnote{A decision problem is said to be undecidable when there does not exist an algorithm that halts on all inputs with the correct answer.}. However, practical reasoning algorithms can be developed that:
\begin{enumerate*}[label=(\roman*),before=\unskip{ i.e., }, itemjoin={{, }}, itemjoin*={{, or }}]
    \item\label{opt_1} halt on any input but may overlook certain entailments,
    \item\label{opt_2} consistently halt with accurate results but only accommodate restricted input ontologies,
    \item\label{opt_3} exclusively yield correct results but may never halt on certain inputs.
\end{enumerate*}

The exploration of Option \ref{opt_3} has been undertaken with the use of theorem provers~\cite{Schneider2011ReasoningOWL2Full}. Options \ref{opt_1} and \ref{opt_2} are more frequently pursued, employing rules or Description Logics. Option \ref{opt_1} is conducive to efficient reasoning, particularly in contexts where data may be incomplete. In contrast, Option \ref{opt_2} may be more suitable in domains where the omission of entailments is deemed undesirable.

\section{Inductive Information}\label{inductive-information}
While deductive knowledge is characterised by precise logical consequences, inductive information concerns the process of generalizing patterns derived from observations to generate novel predictions. Then \term{inductive knowledge} includes both the models used to encode patterns, as well as the predictions made by those models.
A variety of inductive methodologies are applicable to knowledge graphs. Unsupervised techniques leverage graph analytics to identify communities or clusters, as well as to discern central nodes and edges. Knowledge graph embeddings utilize self-supervision to derive low-dimensional numerical representations. The graph structure itself can also be advantageous for supervised learning approaches. Symbolic learning techniques possess the ability to derive symbolic models â i.e., logical formulae in the form of rules or axioms â from graphs in a self-supervised fashion. A discussion of supervised learning techniques applicable to knowledge graphs is presented in the subsequent chapter.